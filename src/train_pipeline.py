import pandas as pd
import joblib
import os

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, roc_auc_score
from xgboost import XGBClassifier

# ‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º MLflow –∏ –º–æ–¥—É–ª—å –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è sklearn-–º–æ–¥–µ–ª–µ–π
import mlflow
import mlflow.sklearn

# üìÅ –ü—É—Ç–∏ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º —Å –¥–∞–Ω–Ω—ã–º–∏ –∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
PROCESSED_DIR = "data/processed/"
MODEL_DIR = "models/"
os.makedirs(MODEL_DIR, exist_ok=True)  # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é models/, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç

# üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –æ–±—É—á–∞—é—â–∏–µ –∏ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
X_train = pd.read_csv(f"{PROCESSED_DIR}/X_train.csv")
X_test = pd.read_csv(f"{PROCESSED_DIR}/X_test.csv")
y_train = pd.read_csv(f"{PROCESSED_DIR}/y_train.csv").values.ravel()
y_test = pd.read_csv(f"{PROCESSED_DIR}/y_test.csv").values.ravel()

# ‚öôÔ∏è –°–æ–∑–¥–∞—ë–º pipeline: –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏ –æ–±—É—á–∞–µ–º XGBoost
pipeline = Pipeline([
    ('scaler', StandardScaler()),  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    ('xgb', XGBClassifier(         # –ú–æ–¥–µ–ª—å XGBoost —Å –±–∞–∑–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        n_estimators=100,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        use_label_encoder=False,
        eval_metric='logloss',
        random_state=42
    ))
])

# üöÄ –°—Ç–∞—Ä—Ç—É–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –≤ MLflow
with mlflow.start_run(run_name="xgb_pipeline_with_registry"):

    # üß† –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    pipeline.fit(X_train, y_train)

    # üìä –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred = pipeline.predict(X_test)
    y_proba = pipeline.predict_proba(X_test)[:, 1]

    # üìà –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
    roc_auc = roc_auc_score(y_test, y_proba)
    print("üìä Classification Report:")
    print(classification_report(y_test, y_pred))
    print(f"ROC-AUC: {roc_auc:.4f}")

    # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫—É ROC-AUC
    mlflow.log_metric("roc_auc", roc_auc)

    # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ (–¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤)
    mlflow.log_params({
        "n_estimators": 100,
        "max_depth": 6,
        "learning_rate": 0.1,
        "subsample": 0.8,
        "colsample_bytree": 0.8
    })

    # ‚úÖ –õ–æ–≥–∏—Ä—É–µ–º –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –≤ MLflow Registry
    mlflow.sklearn.log_model(
        sk_model=pipeline,                  # –û–±—ä–µ–∫—Ç pipeline
        artifact_path="model",              # –í –∫–∞–∫–æ–π –ø–∞–ø–∫–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ MLflow
        registered_model_name="fraud_detector"  # üìå –ò–º—è –º–æ–¥–µ–ª–∏ –≤ MLflow Registry
    )

# üíæ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –ª–æ–∫–∞–ª—å–Ω–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ .joblib
joblib.dump(pipeline, f"{MODEL_DIR}/pipeline_xgb.joblib")
print("‚úÖ Pipeline —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ models/pipeline_xgb.joblib")